---
description: 並列サブエージェントでコンテキスト消費実験を実行
allowed-tools: Bash, Read, Write, Edit, Task
---

# 並列実験実行

`context-experiment-runner` サブエージェントを使用して実験を並列実行します。

## 実験の仕組み

各サブエージェントが：
1. **ノイズチャンクを読み込んでコンテキストを消費**
2. FizzBuzz仕様書を読み込む
3. 実装を生成
4. テストを実行
5. 結果を記録

各エージェントは独立したコンテキストを持つため、コンテキスト消費の影響を正確に計測できます。

## コンテキストレベル

| レベル | 読み込むチャンク数 | 目標消費率 |
|--------|-------------------|-----------|
| 30%    | 48 chunks         | ~30%      |
| 50%    | 80 chunks         | ~50%      |
| 80%    | 128 chunks        | ~80%      |
| 90%    | 144 chunks        | ~90%      |

## 使い方

ユーザーから以下のパラメータを確認してください：

1. **コンテキストレベル**: `30%`, `50%`, `80%`, `90%` のいずれか
2. **並列度**: 同時に実行するエージェント数（推奨: 5-10）
3. **試行範囲**: 開始番号と終了番号（1-100）

## 実行手順

### 1. サブエージェントの起動

Task ツールを使用して、`subagent_type: "context-experiment-runner"` で起動します。

**重要**: 複数のエージェントを**1つのメッセージで同時に**起動することで並列実行を実現します。

各エージェントへのプロンプト例：

```
コンテキストレベル "30%" で試行番号 5 を実行してください。

手順：
1. noise_chunks/chunk_0.txt から chunk_47.txt まで（48個）を読み込む
2. docs/fizzbuzz_spec.md を読む
3. prompts/implementation_prompt.txt を読む
4. src/fizzbuzz.py を実装
5. pytest tests/test_fizzbuzz.py を実行
6. 結果を results/trial_30%_005.json に保存
```

### 2. 並列実行パターン

**例：30%レベルで100試行を10並列で実行**

10個の `context-experiment-runner` エージェントを同時起動：

- エージェント1: 試行1-10
- エージェント2: 試行11-20
- エージェント3: 試行21-30
- ...
- エージェント10: 試行91-100

**重要**: 各エージェントは1試行のみ実行すること（MUST）。コンテキスト分離を保証するため、複数試行を1エージェントで実行してはならない

### 3. 結果の集計

全試行完了後、結果を集計：

```bash
python scripts/analyze_results.py
```

## 注意事項

- 各サブエージェントは独立したコンテキストで開始
- ノイズチャンクの読み込みでコンテキストを消費
- 結果は `results/trial_*.json` に個別保存
- APIレート制限に注意して並列度を調整
- **1試行1エージェント**が必須（MUST）（コンテキスト分離のため）

## ワークスペース分離

並列実行時のファイル競合を防ぐため、各試行は独立したワークスペースを使用：

```
workspaces/
├── trial_30%_001/
│   └── src/fizzbuzz.py
├── trial_30%_002/
│   └── src/fizzbuzz.py
...
```

**MUST NOT**: `src/fizzbuzz.py`に直接書き込まない（競合発生）

## コンテキスト測定

各エージェントは `/context` コマンドを使用してコンテキスト消費量を測定し、結果に記録：

```json
{
  "context_used_tokens": 125000,
  "context_total_tokens": 200000,
  "context_percent": 62.5,
  "context_raw_output": "Context: 62.5% used (125K / 200K tokens)"
}
```
